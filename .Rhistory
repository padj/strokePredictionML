model$ctrl <- caret::trainControl(method = "repeatedcv",
number = 10,
repeats = 3,
verboseIter = FALSE)
# Train the model
for (mdl in xgb_models) {
print(paste0('running ', mdl))
xgb <- caret::train(as.factor(stroke) ~ .,
data = train,
method = mdl,
metric = "Kappa",
trControl = model$ctrl,
verbose = 0)
modellist[[toString(mdl)]] <- xgb
}
# This bit allows us to plot and assess the different models
results <- resamples(modellist)
summary(results)
# We can now save the plot
png(paste0(output_location,image_name,'.png'), width = 800, height = 600)
dotplot(results)
dev.off()
# take best performing
model$xgb <- modellist$xgbLinear
# Apply the model to the test set
predicted <- predict(model$xgb, test)
# Calculate the Confusion Matrix and statistics surrounding the performance of
# our model
model$CM <- caret::confusionMatrix(data = predicted,
reference = as.factor(test$stroke),
positive='1')
print(model$CM) # view confusion matrix
# It's also common to score the performance of the model using the area under
# the ROC curve metric (AUC). We can calculate the ROC directly
ROC_val = pROC::roc(response=test$stroke, predictor=ordered(predicted))
print(ROC_val) # This can be plotted also
# Or just spit out the AUC metric
AUC_val = pROC::auc(response=test$stroke, predictor=ordered(predicted))
print(AUC_val) # A score of 1 is very good, a score of 0.5 is very bad.
model$AUC <- AUC_val
# Add train and test file names for reference and reproducibility.
model$train_file <- train_file
model$test_file <- test_file
# Now that the model is developed/trained, we should save the model, along with
# information about it for use later.
# The list "model" contains the trained model, the control file, the
# confusion matrix and the AUC metric, as well as the names of the train and
# test files used in development of the model.
save(model, file=paste0(output_model_location,output_model_name))
# xgb_models
###############################################################################
# -----------------------------------------------------------------------------
# SCRIPT:
# Name:       xgb_models.R
# Date:       28 June 2021
# Version:    1.0.0
# Authors:    thomas.padgett
#
# Description:
#             Imports prepped, test and train data. Trains using various XGB
#             methods within caret. Tested on the test set. Performance is
#             reviewed using the confusion matrix and AUC metric.
#
# Change notes:
#             N/A
#
# -----------------------------------------------------------------------------
###############################################################################
#### Preamble ####
set.seed(10) # Ensure repeatability
library(pROC)
library(caret)
library(e1071) #required within caret::train()
library(xgboost)
library(plyr)
#library(h2o)
library(gbm)
# We'll use this later to define where we output to.
output_location <- 'output/xgb/'
output_model_location <- 'scripts/MLModels/model_RData/'
output_model_name <- 'xgb_model_Oversampled_FEng_binned_cDP_int.RData'
image_name <- 'xgb_dotplot_Oversampled_FEng_binned_cDP_int'
#### Function definitions ####
#### Import data ####
train_file <- "data/trainData_Oversampled_FEng_binned_cDP_int_v1.csv"
test_file <- "data/testData_Oversampled_FEng_binned_cDP_int_v1.csv"
train <- read.csv(train_file)
test <- read.csv(test_file)
#### Model ####
xgb_models <- c('xgbLinear', 'xgbTree', 'gbm')
# 'gbm_h2o' <- doesn't seem to work.
# Note: xgbDART seems to take forever.
model <- list()
modellist <- list()
# Define the training control method.
# K-fold cross validation (number = folds)
model$ctrl <- caret::trainControl(method = "repeatedcv",
number = 10,
repeats = 3,
verboseIter = FALSE)
# Train the model
for (mdl in xgb_models) {
print(paste0('running ', mdl))
xgb <- caret::train(as.factor(stroke) ~ .,
data = train,
method = mdl,
metric = "Kappa",
trControl = model$ctrl,
verbose = 0)
modellist[[toString(mdl)]] <- xgb
}
# This bit allows us to plot and assess the different models
results <- resamples(modellist)
summary(results)
# We can now save the plot
png(paste0(output_location,image_name,'.png'), width = 800, height = 600)
dotplot(results)
dev.off()
# take best performing
model$xgb <- modellist$xgbLinear
# Apply the model to the test set
predicted <- predict(model$xgb, test)
# Calculate the Confusion Matrix and statistics surrounding the performance of
# our model
model$CM <- caret::confusionMatrix(data = predicted,
reference = as.factor(test$stroke),
positive='1')
print(model$CM) # view confusion matrix
# It's also common to score the performance of the model using the area under
# the ROC curve metric (AUC). We can calculate the ROC directly
ROC_val = pROC::roc(response=test$stroke, predictor=ordered(predicted))
print(ROC_val) # This can be plotted also
# Or just spit out the AUC metric
AUC_val = pROC::auc(response=test$stroke, predictor=ordered(predicted))
print(AUC_val) # A score of 1 is very good, a score of 0.5 is very bad.
model$AUC <- AUC_val
# Add train and test file names for reference and reproducibility.
model$train_file <- train_file
model$test_file <- test_file
# Now that the model is developed/trained, we should save the model, along with
# information about it for use later.
# The list "model" contains the trained model, the control file, the
# confusion matrix and the AUC metric, as well as the names of the train and
# test files used in development of the model.
save(model, file=paste0(output_model_location,output_model_name))
load('scripts/MLModels/model_RData/glm_model_FEng_int.RData')
View(model)
model$CM
model$CM$table
model$CM$positive
model$CM$overall
model$CM$overall[1]
model$CM$byClass
model$CM$byClass[0]
model$CM$byClass[1]
model$CM$byClass[2]
model$AUC
model_type <- 'glm'
rm(model)
data_names <- list.files(data_location)
data_location <- 'scripts/MLModels/model_RData/'
data_names <- list.files(data_location)
class(data_names)
data_names[1]
data_names <- list.files(data_location, pattern = model_type)
for (name in data_names) {
print(name)
}
name <- substr(name,2,3)
name <- substr(data_names[1],2,3)
substr(data_names[1],2,3)
substr(data_names[1],03)
substr(data_names[1],0,)
substr(data_names[1],0,:)
substr(data_names[1],0,end)
substr(data_names[1],1,)
substr(data_names[1],1,10)
substr(data_names[1],1,length(data_names[1])
substr(data_names[1],1,length(data_names[1]))
length(data_names[1])
data_names[1]
data_names[1][1]
data_names[1][1][1]
data_names[1][2]
data_names[1][1]
length(data_names[1][1])
nchar(data_names[1])
substr(data_names[1],1,nchar(data_names[1]))
substr(data_names[1],11,nchar(data_names[1]))
for (name in data_names) {
print(name)
name <- substr(name[1],11,nchar(name[1]))
}
for (name in data_names) {
print(name)
name <- substr(name[1],11,nchar(name[1]))
print(name)
}
for (name in data_names) {
print(name)
name <- substr(name[1],11,nchar(name[1])-5)
print(name)
}
for (name in data_names) {
print(name)
name <- substr(name[1],11,nchar(name[1])-6)
print(name)
}
model_type <- 'glm'
data_location <- 'scripts/MLModels/model_RData/'
data_names <- list.files(data_location, pattern = model_type)
output <- data.frame(matrix(ncol = 7, nrow = 9))
for (i in 1:length(data_names)) {
name <- data_names[i]
load(paste0(data_location,name))
name <- substr(name[1],11,nchar(name[1])-6)
#print(name)
output[i,1] <- 1
}
View(output)
# set model type (xgb, rf, glm, nnet)
# for each .RData file of the model type:
# load the file
# acc <- model$CM$overall[1]
# kap <- model$CM$overall[2]
# sensi <- model$CM$byClass[1]
# speci <- model$CM$byClass[2]
# auc <- model$AUC
model_type <- 'glm'
data_location <- 'scripts/MLModels/model_RData/'
data_names <- list.files(data_location, pattern = model_type)
output <- data.frame(matrix(ncol = 6, nrow = 13))
for (i in 1:length(data_names)) {
name <- data_names[i]
load(paste0(data_location,name))
name <- substr(name[1],11,nchar(name[1])-6)
#print(name)
output[i+1,1] <- name
output[i+1,2] <- model$CM$overall[1] # accuracy
output[i+1,3] <- model$CM$overall[2] # kappa
output[i+1,4] <- model$CM$byClass[1] # sensitivity
output[i+1,5] <- model$CM$byClass[2] # specificity
output[i+1,6] <- model$AUC # AUC
}
View(output)
output[1,2] <- 'Accuracy'
odel_type <- 'glm'
data_location <- 'scripts/MLModels/model_RData/'
data_names <- list.files(data_location, pattern = model_type)
output <- data.frame(matrix(ncol = 6, nrow = 13))
output[1,1] <- model_type
output[1,2] <- 'Accuracy'
output[1,3] <- 'Kappa'
output[1,4] <- 'Sensitivity'
output[1,5] <- 'Specificity'
output[1,6] <- 'AUC'
for (i in 1:length(data_names)) {
name <- data_names[i]
load(paste0(data_location,name))
name <- substr(name[1],11,nchar(name[1])-6)
#print(name)
output[i+1,1] <- name
output[i+1,2] <- model$CM$overall[1] # accuracy
output[i+1,3] <- model$CM$overall[2] # kappa
output[i+1,4] <- model$CM$byClass[1] # sensitivity
output[i+1,5] <- model$CM$byClass[2] # specificity
output[i+1,6] <- model$AUC # AUC
}
model_type <- 'glm'
data_location <- 'scripts/MLModels/model_RData/'
data_names <- list.files(data_location, pattern = model_type)
output <- data.frame(matrix(ncol = 6, nrow = 13))
output[1,1] <- model_type
output[1,2] <- 'Accuracy'
output[1,3] <- 'Kappa'
output[1,4] <- 'Sensitivity'
output[1,5] <- 'Specificity'
output[1,6] <- 'AUC'
for (i in 1:length(data_names)) {
name <- data_names[i]
load(paste0(data_location,name))
name <- substr(name[1],11,nchar(name[1])-6)
#print(name)
output[i+1,1] <- name
output[i+1,2] <- model$CM$overall[1] # accuracy
output[i+1,3] <- model$CM$overall[2] # kappa
output[i+1,4] <- model$CM$byClass[1] # sensitivity
output[i+1,5] <- model$CM$byClass[2] # specificity
output[i+1,6] <- model$AUC # AUC
}
View(output)
model_types <- c('glm', 'rf', 'nnet', 'xgb')
data_location <- 'scripts/MLModels/model_RData/'
for (model_type in model_types) {
data_names <- list.files(data_location, pattern = model_type)
output <- data.frame(matrix(ncol = 6, nrow = 13))
output[1,1] <- model_type
output[1,2] <- 'Accuracy'
output[1,3] <- 'Kappa'
output[1,4] <- 'Sensitivity'
output[1,5] <- 'Specificity'
output[1,6] <- 'AUC'
for (i in 1:length(data_names)) {
name <- data_names[i]
load(paste0(data_location,name))
name <- substr(name[1],11,nchar(name[1])-6)
output[i+1,1] <- name
output[i+1,2] <- model$CM$overall[1] # accuracy
output[i+1,3] <- model$CM$overall[2] # kappa
output[i+1,4] <- model$CM$byClass[1] # sensitivity
output[i+1,5] <- model$CM$byClass[2] # specificity
output[i+1,6] <- model$AUC # AUC
}
file_name <- paste0(model_type,'_table_output.csv')
write.csv(output, paste0('output/', file_name))
}
data_names
model_types <- c('glm', 'rf', 'nnet', 'xgb')
data_location <- 'scripts/MLModels/model_RData/'
for (model_type in model_types) {
data_names <- list.files(data_location, pattern = model_type)
output <- data.frame(matrix(ncol = 6, nrow = 13))
output[1,1] <- model_type
output[1,2] <- 'Accuracy'
output[1,3] <- 'Kappa'
output[1,4] <- 'Sensitivity'
output[1,5] <- 'Specificity'
output[1,6] <- 'AUC'
for (i in 1:length(data_names)) {
name <- data_names[i]
load(paste0(data_location,name))
name <- substr(name[1],nchar(model_type)+8,nchar(name[1])-6)
output[i+1,1] <- name
output[i+1,2] <- model$CM$overall[1] # accuracy
output[i+1,3] <- model$CM$overall[2] # kappa
output[i+1,4] <- model$CM$byClass[1] # sensitivity
output[i+1,5] <- model$CM$byClass[2] # specificity
output[i+1,6] <- model$AUC # AUC
}
file_name <- paste0(model_type,'_table_output.csv')
write.csv(output, paste0('output/', file_name))
}
model_types <- c('glm', 'rf', 'nnet', 'xgb')
data_location <- 'scripts/MLModels/model_RData/'
for (model_type in model_types) {
data_names <- list.files(data_location, pattern = model_type)
output <- data.frame(matrix(ncol = 6, nrow = 13))
output[1,1] <- model_type
output[1,2] <- 'Accuracy'
output[1,3] <- 'Kappa'
output[1,4] <- 'Sensitivity'
output[1,5] <- 'Specificity'
output[1,6] <- 'AUC'
for (i in 1:length(data_names)) {
name <- data_names[i]
load(paste0(data_location,name))
name <- substr(name[1],nchar(model_type)+8,nchar(name[1])-6)
output[i+1,1] <- name
output[i+1,2] <- model$CM$overall[1] # accuracy
output[i+1,3] <- model$CM$overall[2] # kappa
output[i+1,4] <- model$CM$byClass[1] # sensitivity
output[i+1,5] <- model$CM$byClass[2] # specificity
output[i+1,6] <- model$AUC # AUC
}
file_name <- paste0(model_type,'_table_output.csv')
write.csv(output, paste0('output/', file_name),
row.names = FALSE, col.names = FALSE)
}
model_types <- c('glm', 'rf', 'nnet', 'xgb')
data_location <- 'scripts/MLModels/model_RData/'
for (model_type in model_types) {
data_names <- list.files(data_location, pattern = model_type)
output <- data.frame(matrix(ncol = 6, nrow = 13))
output[1,1] <- model_type
output[1,2] <- 'Accuracy'
output[1,3] <- 'Kappa'
output[1,4] <- 'Sensitivity'
output[1,5] <- 'Specificity'
output[1,6] <- 'AUC'
for (i in 1:length(data_names)) {
name <- data_names[i]
load(paste0(data_location,name))
name <- substr(name[1],nchar(model_type)+8,nchar(name[1])-6)
output[i+1,1] <- name
output[i+1,2] <- model$CM$overall[1] # accuracy
output[i+1,3] <- model$CM$overall[2] # kappa
output[i+1,4] <- model$CM$byClass[1] # sensitivity
output[i+1,5] <- model$CM$byClass[2] # specificity
output[i+1,6] <- model$AUC # AUC
}
file_name <- paste0(model_type,'_table_output.csv')
write.table(output, paste0('output/', file_name),
row.names = FALSE, col.names = FALSE)
}
write.table(output, paste0('output/', file_name), sep = " ",
row.names = FALSE, col.names = FALSE)
write.table(output, paste0('output/', file_name), sep = " ",
row.names = FALSE, col.names = FALSE)
?write.table
write.table(output, paste0('output/', file_name), sep = " ", quote = FALSE,
row.names = FALSE, col.names = FALSE)
View(output)
View(output)
model_types <- c('glm', 'rf', 'nnet', 'xgb')
data_location <- 'scripts/MLModels/model_RData/'
for (model_type in model_types) {
data_names <- list.files(data_location, pattern = model_type)
output <- data.frame(matrix(ncol = 6, nrow = 13))
output[1,1] <- model_type
output[1,2] <- 'Accuracy'
output[1,3] <- 'Kappa'
output[1,4] <- 'Sensitivity'
output[1,5] <- 'Specificity'
output[1,6] <- 'AUC'
for (i in 1:length(data_names)) {
name <- data_names[i]
load(paste0(data_location,name))
name <- substr(name[1],nchar(model_type)+8,nchar(name[1])-6)
output[i+1,1] <- name
output[i+1,2] <- model$CM$overall[1] # accuracy
output[i+1,3] <- model$CM$overall[2] # kappa
output[i+1,4] <- model$CM$byClass[1] # sensitivity
output[i+1,5] <- model$CM$byClass[2] # specificity
output[i+1,6] <- model$AUC # AUC
}
file_name <- paste0(model_type,'_table_output.csv')
write.table(output, paste0('output/', file_name), sep = " ", quote = FALSE,
row.names = FALSE, col.names = FALSE)
}
output <- table()
output <- table(output)
output
?table
model_types <- c('glm', 'rf', 'nnet', 'xgb')
data_location <- 'scripts/MLModels/model_RData/'
for (model_type in model_types) {
data_names <- list.files(data_location, pattern = model_type)
output <- data.frame(matrix(ncol = 6, nrow = 13))
output[1,1] <- model_type
output[1,2] <- 'Accuracy'
output[1,3] <- 'Kappa'
output[1,4] <- 'Sensitivity'
output[1,5] <- 'Specificity'
output[1,6] <- 'AUC'
for (i in 1:length(data_names)) {
name <- data_names[i]
load(paste0(data_location,name))
name <- substr(name[1],nchar(model_type)+8,nchar(name[1])-6)
output[i+1,1] <- name
output[i+1,2] <- model$CM$overall[1] # accuracy
output[i+1,3] <- model$CM$overall[2] # kappa
output[i+1,4] <- model$CM$byClass[1] # sensitivity
output[i+1,5] <- model$CM$byClass[2] # specificity
output[i+1,6] <- model$AUC # AUC
}
file_name <- paste0(model_type,'_table_output.csv')
write.table(output, paste0('output/', file_name), sep = " ", quote = FALSE,
row.names = FALSE, col.names = FALSE, eol = '\n')
}
A <- as.table(output)
model_types <- c('glm', 'rf', 'nnet', 'xgb')
data_location <- 'scripts/MLModels/model_RData/'
for (model_type in model_types) {
data_names <- list.files(data_location, pattern = model_type)
output <- data.frame(matrix(ncol = 6, nrow = 13))
output[1,1] <- model_type
output[1,2] <- 'Accuracy'
output[1,3] <- 'Kappa'
output[1,4] <- 'Sensitivity'
output[1,5] <- 'Specificity'
output[1,6] <- 'AUC'
for (i in 1:length(data_names)) {
name <- data_names[i]
load(paste0(data_location,name))
name <- substr(name[1],nchar(model_type)+8,nchar(name[1])-6)
output[i+1,1] <- name
output[i+1,2] <- model$CM$overall[1] # accuracy
output[i+1,3] <- model$CM$overall[2] # kappa
output[i+1,4] <- model$CM$byClass[1] # sensitivity
output[i+1,5] <- model$CM$byClass[2] # specificity
output[i+1,6] <- model$AUC # AUC
}
file_name <- paste0(model_type,'_table_output.csv')
write.csv(output, paste0('output/', file_name), sep = " ", quote = FALSE,
row.names = FALSE, col.names = FALSE, eol = '\n')
}
model_types <- c('glm', 'rf', 'nnet', 'xgb')
data_location <- 'scripts/MLModels/model_RData/'
for (model_type in model_types) {
data_names <- list.files(data_location, pattern = model_type)
output <- data.frame(matrix(ncol = 6, nrow = 13))
output[1,1] <- model_type
output[1,2] <- 'Accuracy'
output[1,3] <- 'Kappa'
output[1,4] <- 'Sensitivity'
output[1,5] <- 'Specificity'
output[1,6] <- 'AUC'
for (i in 1:length(data_names)) {
name <- data_names[i]
load(paste0(data_location,name))
name <- substr(name[1],nchar(model_type)+8,nchar(name[1])-6)
output[i+1,1] <- name
output[i+1,2] <- model$CM$overall[1] # accuracy
output[i+1,3] <- model$CM$overall[2] # kappa
output[i+1,4] <- model$CM$byClass[1] # sensitivity
output[i+1,5] <- model$CM$byClass[2] # specificity
output[i+1,6] <- model$AUC # AUC
}
file_name <- paste0(model_type,'_table_output.csv')
write.csv(output, paste0('output/', file_name), quote = FALSE,
row.names = FALSE)
}
